{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f675d20e-c828-4d04-b01b-f2d191d3a991",
   "metadata": {},
   "source": [
    "# Изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19bb42c6-5a88-40dd-94f1-759cbcf751b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 960, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio.v3 as iio\n",
    "\n",
    "img_arr = iio.imread('/home/avtotka/Pictures/hurrem.jpg')\n",
    "img_arr.shape # ширина * высота * каналы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e515205-24aa-43ea-8254-42252ff15f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1280, 960])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2, 0, 1) # перестановка на каналы * высота * ширина (стандарт для PyTorch)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68626e6e-cde0-4a63-815a-2837cc742cad",
   "metadata": {},
   "source": [
    "Для более эффективной загрузки нескольких изображений - выделить память заранее под тензор нужного размера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bbf326e-58a4-4283-9e1e-86ad5638e55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 1280, 960])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 1280, 960, dtype=torch.uint8)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efdee3fd-f844-4d33-ac28-873055469d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '/home/avtotka/Pictures/960x1280'\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.jpg']\n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = iio.imread(os.path.join(data_dir, filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    img_t = img_t[:3] # убираю альфа канал если есть\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d8f892-24ad-4ce8-85e2-6b5a882dd2c0",
   "metadata": {},
   "source": [
    "## Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f95550f3-8fbe-46f4-a061-e900342ffe2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.9638,  0.7653,  0.6931,  ...,  1.3427,  1.1984,  0.9999],\n",
       "          [ 0.9999,  0.9457,  0.7833,  ...,  1.2344,  1.1803,  1.0720],\n",
       "          [ 1.1262,  1.1803,  0.9638,  ...,  1.1262,  1.1442,  1.1081],\n",
       "          ...,\n",
       "          [ 0.2239,  0.2419,  0.2780,  ...,  0.1698,  0.0976,  0.0434],\n",
       "          [ 0.2600,  0.3141,  0.3502,  ...,  0.0976,  0.0976,  0.1156],\n",
       "          [ 0.3322,  0.3863,  0.4404,  ...,  0.0434,  0.0976,  0.1698]],\n",
       "\n",
       "         [[ 0.7973,  0.6090,  0.5336,  ...,  1.2494,  1.0987,  0.9104],\n",
       "          [ 0.8350,  0.7973,  0.6278,  ...,  1.1552,  1.1176,  1.0045],\n",
       "          [ 0.9857,  1.0422,  0.8162,  ...,  1.0799,  1.0987,  1.0610],\n",
       "          ...,\n",
       "          [-0.2952, -0.2763, -0.2387,  ..., -0.3329, -0.4082, -0.4647],\n",
       "          [-0.2575, -0.2010, -0.1633,  ..., -0.4082, -0.4082, -0.3894],\n",
       "          [-0.1822, -0.1257, -0.0691,  ..., -0.4647, -0.4082, -0.3329]],\n",
       "\n",
       "         [[-0.6616, -0.8720, -0.9367,  ..., -0.5807, -0.7102, -0.9206],\n",
       "          [-0.6292, -0.7102, -0.8882,  ..., -0.6131, -0.6940, -0.7911],\n",
       "          [-0.5483, -0.5321, -0.7263,  ..., -0.5807, -0.5645, -0.6292],\n",
       "          ...,\n",
       "          [-0.9853, -0.9853, -0.9853,  ..., -0.9044, -0.9691, -0.9853],\n",
       "          [-0.9853, -0.9529, -0.9206,  ..., -0.9691, -0.9691, -0.9529],\n",
       "          [-0.9367, -0.8882, -0.8396,  ..., -0.9853, -0.9691, -0.9044]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4765,  0.5307,  0.5848,  ...,  0.6029,  0.7653,  0.8735],\n",
       "          [ 0.4765,  0.5126,  0.5848,  ...,  0.5848,  0.7472,  0.8735],\n",
       "          [ 0.4765,  0.5126,  0.5668,  ...,  0.5848,  0.7472,  0.8555],\n",
       "          ...,\n",
       "          [-0.2633, -0.2814, -0.2814,  ...,  1.3969,  1.3969,  1.3788],\n",
       "          [-0.2453, -0.2633, -0.2814,  ...,  1.4149,  1.3969,  1.3788],\n",
       "          [-0.2092, -0.2453, -0.2633,  ...,  1.4149,  1.3969,  1.3788]],\n",
       "\n",
       "         [[ 0.4771,  0.5336,  0.5901,  ...,  0.9669,  1.0987,  1.2117],\n",
       "          [ 0.4771,  0.5148,  0.5901,  ...,  0.9480,  1.0799,  1.2117],\n",
       "          [ 0.4771,  0.5148,  0.5713,  ...,  0.9480,  1.0799,  1.1929],\n",
       "          ...,\n",
       "          [-0.2575, -0.2763, -0.2763,  ...,  1.7015,  1.7015,  1.6826],\n",
       "          [-0.2387, -0.2575, -0.2763,  ...,  1.7203,  1.7015,  1.6826],\n",
       "          [-0.2010, -0.2387, -0.2575,  ...,  1.7203,  1.7015,  1.6826]],\n",
       "\n",
       "         [[ 0.6170,  0.6655,  0.7141,  ...,  1.4262,  1.5071,  1.6042],\n",
       "          [ 0.6170,  0.6493,  0.7141,  ...,  1.4100,  1.4909,  1.6042],\n",
       "          [ 0.6170,  0.6493,  0.6979,  ...,  1.4100,  1.4909,  1.5880],\n",
       "          ...,\n",
       "          [ 0.0505,  0.0343,  0.0343,  ...,  1.9117,  1.9117,  1.8955],\n",
       "          [ 0.0667,  0.0505,  0.0343,  ...,  1.9279,  1.9117,  1.8955],\n",
       "          [ 0.0991,  0.0667,  0.0505,  ...,  1.9279,  1.9117,  1.8955]]],\n",
       "\n",
       "\n",
       "        [[[-0.0829, -0.1009, -0.1190,  ..., -0.7325, -0.9310, -1.2558],\n",
       "          [-0.2092, -0.2272, -0.2272,  ..., -0.8408, -1.0213, -1.0754],\n",
       "          [-0.2633, -0.2814, -0.2814,  ..., -1.1115, -1.1837, -0.9130],\n",
       "          ...,\n",
       "          [-1.3822, -1.4183, -1.3822,  ...,  1.7397,  1.7397,  1.7397],\n",
       "          [-1.4363, -1.4544, -1.4183,  ...,  1.7397,  1.7397,  1.7397],\n",
       "          [-1.5265, -1.5446, -1.4724,  ...,  1.7397,  1.7397,  1.7397]],\n",
       "\n",
       "         [[ 0.2888,  0.2699,  0.2511,  ..., -0.7473, -0.9545, -1.2935],\n",
       "          [ 0.1569,  0.1381,  0.1381,  ..., -0.8603, -1.0486, -1.1051],\n",
       "          [ 0.1004,  0.0816,  0.0816,  ..., -1.1428, -1.2182, -0.9356],\n",
       "          ...,\n",
       "          [-0.9733, -1.0110, -0.9733,  ...,  2.0782,  2.0782,  2.0782],\n",
       "          [-1.0298, -1.0486, -1.0110,  ...,  2.0782,  2.0782,  2.0782],\n",
       "          [-1.1240, -1.1428, -1.0675,  ...,  2.0782,  2.0782,  2.0782]],\n",
       "\n",
       "         [[ 0.7950,  0.7788,  0.7626,  ..., -0.3217, -0.4998, -0.7911],\n",
       "          [ 0.6817,  0.6655,  0.6655,  ..., -0.4188, -0.5807, -0.6292],\n",
       "          [ 0.6331,  0.6170,  0.6170,  ..., -0.6616, -0.7263, -0.4836],\n",
       "          ...,\n",
       "          [-0.1923, -0.2246, -0.1923,  ...,  2.4943,  2.4943,  2.4943],\n",
       "          [-0.2408, -0.2570, -0.2246,  ...,  2.4943,  2.4943,  2.4943],\n",
       "          [-0.3217, -0.3379, -0.2732,  ...,  2.4943,  2.4943,  2.4943]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batch.float()\n",
    "\n",
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])\n",
    "    batch[:, c] = (batch[:, c] - mean) / std\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2532098-d586-41fc-83eb-e42c42ddcad1",
   "metadata": {},
   "source": [
    "# Таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fd63a23-1452-47a8-8f19-b83d389e0773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]],\n",
       "      shape=(4898, 12), dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "wine_path = '/home/avtotka/dev/ai/pytorch/winequality-white.csv'\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=';', skiprows=1)\n",
    "\n",
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "883f308d-42dd-47b1-8cce-0f4d5d766920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12),\n",
       " ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol',\n",
       "  'quality'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
    "wineq_numpy.shape, col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2606b3f-a19c-4e1b-a464-269e70742c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74039f07-8f25-4f66-a44b-4367698b2a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wineq[:, :-1] # все строки и столбцы кроме последнего (без quality)\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8307e70-1acb-4af3-a49d-5930df861eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 6., 6.,  ..., 6., 7., 6.]), torch.Size([4898]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1] # только оценки\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd35b627-c7a3-48c3-8f8b-d378926f8d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = target.long()\n",
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)\n",
    "\n",
    "target_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "55eb59be-adc7-431e-92c1-a5c799903fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 0., 0., 0., 0.],\n",
       "        [0., 5., 0., 0., 0.],\n",
       "        [0., 0., 6., 0., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.tensor([[0, 1, 2]])\n",
    "value = torch.tensor([[4., 5., 6.]])\n",
    "torch.zeros(3, 5).scatter_(0, index, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d5b93-19a9-47df-b300-8dec23723e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
